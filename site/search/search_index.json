{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Preface","text":""},{"location":"#solutions-to-introduction-to-algorithms-third-edition","title":"Solutions to Introduction to Algorithms Third Edition","text":"\ud83d\udcda A crowdsourced work contributed from nice people all around the world."},{"location":"#getting-started","title":"Getting Started","text":"<p>This website contains nearly complete solutions to the bible textbook - Introduction to Algorithms Third Edition, published by Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein.</p> <p>I hope to organize solutions to help people and myself study algorithms. By using Markdown (.md) files and KaTeX math library, this page is much more readable on portable devices.</p> <p>\"Many a little makes a mickle.\"</p>"},{"location":"#contributors","title":"Contributors","text":"<p>Thanks to the authors of CLRS Solutions, Michelle Bodnar (who writes the even-numbered problems) and Andrew Lohr (who writes the odd-numbered problems), @skanev, @CyberZHG, @yinyanghu, @Gutdub, etc.</p> <p>Thanks to all contributors on GitHub, you guys make this repository a better reference!</p> <p>Special thanks to @JeffreyCA, who fixed math rendering on iOS Safari in #26.</p> <p>If I miss your name here, please tell me!</p>"},{"location":"#motivation","title":"Motivation","text":"<p>I build this website since I want to help everyone learn algorithms by providing something easy to read on mobile devices.</p> <p>Therefore, if any adjustment is needed or you have the same motivation to contribute to this work, please don't hesitate to give me your feedback. You can press the \"pencil icon\" in the upper right corner to edit the content or open an issue in this repository. Your solution will be rebased after I review it and make some form modifications to your pull request.</p> <p>There're lots of issues regarding to solutions in this repository, if you have time, please take a look and try to help people on the internet :)</p> <p>Thank you very much, and I hope that everyone will learn algorithms smoothly.</p>"},{"location":"#how-i-generate-the-website","title":"How I Generate the Website?","text":"<p>I use the static site generator MkDocs and the beautiful theme Material for MkDocs to build this website.</p> <p>As for rendering math equations, I use KaTeX, which is fast and beautiful.</p> <p>I also add <code>overflow-x: auto</code> to prevent the overflow issue on small screen devices so that you can scroll horizontally in the math display equations.</p>"},{"location":"#more-information","title":"More Information","text":"<p>For a clear commit history, I rebase my repository regularly. Therefore, if you have forked the repository before, consider re-forking it again.</p> <p>For more information, please visit my GitHub.</p> <p>Updated to this new page on April 13, 2018, at 04:48 (GMT+8).</p> <p>Revised on July 21, 2019.</p>"},{"location":"#license","title":"License","text":"<p>Licensed under the MIT License.</p>"},{"location":"Chap01/1.1/","title":"1.1 Algorithms","text":""},{"location":"Chap01/1.1/#11-1","title":"1.1-1","text":"<p>Give a real-world example that requires sorting or a real-world example that requires computing a convex hull.</p> <ul> <li>Sorting: browse the price of the restaurants with ascending prices on NTU street.</li> <li>Convex hull: computing the diameter of set of points.</li> </ul>"},{"location":"Chap01/1.1/#11-2","title":"1.1-2","text":"<p>Other than speed, what other measures of efficiency might one use in a real-world setting?</p> <p>Memory efficiency and coding efficiency.</p>"},{"location":"Chap01/1.1/#11-3","title":"1.1-3","text":"<p>Select a data structure that you have seen previously, and discuss its strengths and limitations.</p> <p>Linked-list:</p> <ul> <li>Strengths: insertion and deletion.</li> <li>Limitations: random access.</li> </ul>"},{"location":"Chap01/1.1/#11-4","title":"1.1-4","text":"<p>How are the shortest-path and traveling-salesman problems given above similar? How are they different?</p> <ul> <li>Similar: finding path with shortest distance.</li> <li>Different: traveling-salesman has more constraints.</li> </ul>"},{"location":"Chap01/1.1/#11-5","title":"1.1-5","text":"<p>Come up with a real-world problem in which only the best solution will do. Then come up with one in which a solution that is \"approximately\" the best is good enough.</p> <ul> <li>Best: find the GCD of two positive integer numbers.</li> <li>Approximately: find the solution of differential equations.</li> </ul>"},{"location":"Chap01/1.2/","title":"1.2 Algorithms as a technology","text":""},{"location":"Chap01/1.2/#12-1","title":"1.2-1","text":"<p>Give an example of an application that requires algorithmic content at the application level, and discuss the function of the algorithms involved.</p> <p>Drive navigation.</p>"},{"location":"Chap01/1.2/#12-2","title":"1.2-2","text":"<p>Suppose we are comparing implementations of insertion sort and merge sort on the same machine. For inputs of size $n$ , insertion sort runs in $8n^2$ steps, while merge sort runs in $64n\\lg n$ steps. For which values of $n$ does insertion sort beat merge sort?</p> <p>$$ \\begin{aligned}     8n^2 &amp; &lt;   64n\\lg n \\\\      2^n &amp; &lt;   n^8 \\\\  2 \\le n &amp; \\le 43. \\end{aligned} $$</p>"},{"location":"Chap01/1.2/#12-3","title":"1.2-3","text":"<p>What is the smallest value of $n$ such that an algorithm whose running time is $100n^2$ runs faster than an algorithm whose running time is $2^n$ on the same machine?</p> <p>$$ \\begin{aligned} 100n^2 &amp; &lt;   2^n \\\\      n &amp; \\ge 15. \\end{aligned} $$</p>"},{"location":"Chap01/Problems/1-1/","title":"Problem 1-1","text":"<p>For each function $f(n)$ and time $t$ in the following table, determine the largest size $n$ of a problem that can be solved in time $t$, assuming that the algorithm to solve the problem takes $f(n)$ microseconds.</p> <p>$$ \\begin{array}{cccccccc}          &amp; \\text{1 second}  &amp; \\text{1 minute}    &amp; \\text{1 hour}       &amp; \\text{1 day}            &amp; \\text{1 month}          &amp; \\text{1 year}           &amp; \\text{1 century} \\\\ \\hline \\lg n    &amp; 2^{10^6}         &amp; 2^{6 \\times 10^7}  &amp; 2^{3.6 \\times 10^9} &amp; 2^{8.64 \\times 10^{10}} &amp; 2^{2.59 \\times 10^{12}} &amp; 2^{3.15 \\times 10^{13}} &amp; 2^{3.15 \\times 10^{15}} \\\\ \\sqrt n  &amp; 10^{12}          &amp; 3.6 \\times 10^{15} &amp; 1.3 \\times 10^{19}  &amp; 7.46 \\times 10^{21}     &amp; 6.72 \\times 10^{24}     &amp; 9.95 \\times 10^{26}     &amp; 9.95 \\times 10^{30} \\\\ n        &amp; 10^6             &amp; 6 \\times 10^7      &amp; 3.6 \\times 10^9     &amp; 8.64 \\times 10^{10}     &amp; 2.59 \\times 10^{12}     &amp; 3.15 \\times 10^{13}     &amp; 3.15 \\times 10^{15} \\\\ n\\lg n   &amp; 6.24 \\times 10^4 &amp; 2.8 \\times 10^6    &amp; 1.33 \\times 10^8    &amp; 2.76 \\times 10^9        &amp; 7.19 \\times 10^{10}     &amp; 7.98 \\times 10^{11}     &amp; 6.86 \\times 10^{13} \\\\ n^2      &amp; 1000             &amp; 7745               &amp; 60000               &amp; 293938                  &amp; 1609968                 &amp; 5615692                 &amp; 56156922 \\\\ n^3      &amp; 100              &amp; 391                &amp; 1532                &amp; 4420                    &amp; 13736                   &amp; 31593                   &amp; 146645 \\\\ 2^n      &amp; 19               &amp; 25                 &amp; 31                  &amp; 36                      &amp; 41                      &amp; 44                      &amp; 51 \\\\ n!       &amp; 9                &amp; 11                 &amp; 12                  &amp; 13                      &amp; 15                      &amp; 16                      &amp; 17 \\end{array} $$</p>"},{"location":"Chap02/2.1/","title":"2.1 Insertion sort","text":""},{"location":"Chap02/2.1/#21-1","title":"2.1-1","text":"<p>Using Figure 2.2 as a model, illustrate the operation of $\\text{INSERTION-SORT}$ on the array $A = \\langle 31, 41, 59, 26, 41, 58 \\rangle$.</p> <p></p> <p>The operation of $\\text{INSERTION-SORT}$ on the array $A = \\langle 31, 41, 59, 26, 41, 58 \\rangle$. Array indices appear above the rectangles, and values stored in the array positions appear within the rectangles.</p> <p>(a)-(e) are iterations of the for loop of lines 1-8.</p> <p>In each iteration, the black rectangle holds the key taken from $A[i]$, which is compared with the values in shaded rectangles to its left in the test of line 5. Dotted arrows show array values moved one position to the right in line 6. and solid arrows indicate where the key moves to in line 8.</p> <p>(f) is the final sorted array.</p> <p>The changes of array A during traversal: $$ \\begin{aligned} A &amp; = \\langle 31, 41, 59, 26, 41, 58 \\rangle \\\\ A &amp; = \\langle 31, 41, 59, 26, 41, 58 \\rangle \\\\ A &amp; = \\langle 31, 41, 59, 26, 41, 58 \\rangle \\\\ A &amp; = \\langle 26, 31, 41, 59, 41, 58 \\rangle \\\\ A &amp; = \\langle 26, 31, 41, 41, 59, 58 \\rangle \\\\ A &amp; = \\langle 26, 31, 41, 41, 58, 59 \\rangle \\end{aligned} $$</p>"},{"location":"Chap02/2.1/#21-2","title":"2.1-2","text":"<p>Rewrite the $\\text{INSERTION-SORT}$ procedure to sort into nonincreasing instead of nondecreasing order.</p> <pre><code>INSERTION-SORT(A)\n    for j = 2 to A.length\n        key = A[j]\n        i = j - 1\n        while i &gt; 0 and A[i] &lt; key\n            A[i + 1] = A[i]\n            i = i - 1\n        A[i + 1] = key\n</code></pre>"},{"location":"Chap02/2.1/#21-3","title":"2.1-3","text":"<p>Consider the searching problem:</p> <p>Input: A sequence of $n$ numbers $A = \\langle a_1, a_2, \\ldots, a_n \\rangle$ and a value $v$.</p> <p>Output: An index $i$ such that $v = A[i]$ or the special value $\\text{NIL}$ if $v$ does not appear in $A$.</p> <p>Write pseudocode for linear search, which scans through the sequence, looking for $v$. Using a loop invariant, prove that your algorithm is correct. Make sure that your loop invariant fulfills the three necessary properties.</p> <pre><code>LINEAR-SEARCH(A, v)\n    for i = 1 to A.length\n       if A[i] == v\n            return i\n    return NIL\n</code></pre> <p>Loop invariant: At the start of each iteration of the for loop, the subarray $A[1..i - 1]$ consists of elements that are different than $v$.</p> <p>Initialization: Before the first loop iteration ($i = 1$), the subarray is the empty array, so the proof is trivial.</p> <p>Maintenance: During each loop iteration, we compare $v$ with $A[i]$. If they are the same, we return $i$, which is the correct result. Otherwise, we continue to the next iteration of the loop. At the end of each loop iteration, we know the subarray $A[1..i]$ does not contain $v$, so the loop invariant holds true. Incrementing $i$ for the next iteration of the for loop then preserves the loop invariant.</p> <p>Termination: The loop terminates when $i &gt; A.length = n$. Since $i$ increases by $1$, we must have $i = n + 1$ at that time. Substituting $n + 1$, for $i$ in the wording of the loop invariant, we have that the subarray $A[1..n]$ consists of elements that are different than $v$. Thus, we return $\\text{NIL}$. Observing that $A[1..n]$, we conclude that the entire array does not have any element equal to $v$. Hence the algorithm is correct.</p>"},{"location":"Chap02/2.1/#21-4","title":"2.1-4","text":"<p>Consider the problem of adding two $n$-bit binary integers, stored in two $n$-element arrays $A$ and $B$. The sum of the two integers should be stored in binary form in an $(n + 1)$-element array $C$. State the problem formally and write pseudocode for adding the two integers.</p> <p>Input: An array of booleans $A = \\langle a_1, a_2, \\ldots, a_n \\rangle$ and an array of booleans $B = \\langle b_1, b_2, \\ldots, b_n \\rangle$, each representing an integer stored in binary format (each digit is a number, either $0$ or $1$, least-significant digit first) and each of length $n$.</p> <p>Output: An array $C = \\langle c_1, c_2, \\ldots, c_{n + 1} \\rangle$ such that $C' = A' + B'$ where $A'$, $B'$ and $C'$ are the integers, represented by $A$, $B$ and $C$.</p> <pre><code>ADD-BINARY(A, B)\n    carry = 0\n    for i = 1 to A.length\n        sum = A[i] + B[i] + carry\n        C[i] = sum % 2  // remainder\n        carry = sum / 2 // quotient\n    C[A.length + 1] = carry\n    return C\n</code></pre>"},{"location":"Chap02/2.2/","title":"2.2 Analyzing algorithms","text":""},{"location":"Chap02/2.2/#22-1","title":"2.2-1","text":"<p>Express the function $n^3 / 1000 - 100n^2 - 100n + 3$ in terms of $\\Theta$-notation.</p> <p>$\\Theta(n^3)$.</p>"},{"location":"Chap02/2.2/#22-2","title":"2.2-2","text":"<p>Consider sorting $n$ numbers stored in array $A$ by first finding the smallest element of $A$ and exchanging it with the element in $A[1]$. Then find the second smallest element of $A$, and exchange it with $A[2]$. Continue in this manner for the first $n - 1$ elements of $A$. Write pseudocode for this algorithm, which is known as selection sort. What loop invariant does this algorithm maintain? Why does it need to run for only the first $n - 1$ elements, rather than for all $n$ elements? Give the best-case and worst-case running times of selection sort in $\\Theta$-notation.</p> <ul> <li> <p>Pseudocode:</p> <pre><code>n = A.length\nfor i = 1 to n - 1\n    minIndex = i\n    for j = i + 1 to n\n        if A[j] &lt; A[minIndex]\n            minIndex = j\n    swap(A[i], A[minIndex])\n</code></pre> </li> <li> <p>Loop invariant:</p> <p>At the start of the loop in line 1, the subarray $A[1..i - 1]$ consists of the smallest $i - 1$ elements in array $A$ with sorted order.</p> </li> <li> <p>Why does it need to run for only the first $n - 1$ elements, rather than for all $n$ elements?</p> <p>After $n - 1$ iterations, the subarray $A[1..n - 1]$ consists of the smallest $i - 1$ elements in array $A$ with sorted order. Therefore, $A[n]$ is already the largest element.</p> </li> <li> <p>Running time: $\\Theta(n^2)$.</p> </li> </ul>"},{"location":"Chap02/2.2/#22-3","title":"2.2-3","text":"<p>Consider linear search again (see Exercise 2.1-3). How many elements of the input sequence need to be checked on the average, assuming that the element being searched for is equally likely to be any element in the array? How about in the worst case? What are the average-case and worst-case running times of linear search in $\\Theta$-notation? Justify your answers.</p> <p>If the element is present in the sequence, half of the elements are likely to be checked before it is found in the average case. In the worst case, all of them will be checked. That is, $n / 2$ checks for the average case and $n$ for the worst case. Both of them are $\\Theta(n)$.</p>"},{"location":"Chap02/2.2/#22-4","title":"2.2-4","text":"<p>How can we modify almost any algorithm to have a good best-case running time?</p> <p>You can modify any algorithm to have a best case time complexity by adding a special case. If the input matches this special case, return the pre-computed answer.</p>"},{"location":"Chap02/2.3/","title":"2.3 Designing algorithms","text":""},{"location":"Chap02/2.3/#23-1","title":"2.3-1","text":"<p>Using Figure 2.4 as a model, illustrate the operation of merge sort on the array $A = \\langle 3, 41, 52, 26, 38, 57, 9, 49 \\rangle$.</p> <p>$$[3] \\quad [41] \\quad [52] \\quad [26] \\quad [38] \\quad [57] \\quad [9] \\quad [49]$$</p> <p>$$\\downarrow$$</p> <p>$$[3|41] \\quad [26|52] \\quad [38|57] \\quad [9|49]$$</p> <p>$$\\downarrow$$</p> <p>$$[3|26|41|52] \\quad [9|38|49|57]$$</p> <p>$$\\downarrow$$</p> <p>$$[3|9|26|38|41|49|52|57]$$</p>"},{"location":"Chap02/2.3/#23-2","title":"2.3-2","text":"<p>Rewrite the $\\text{MERGE}$ procedure so that it does not use sentinels, instead stopping once either array $L$ or $R$ has had all its elements copied back to $A$ and then copying the remainder of the other array back into $A$.</p> <pre><code>MERGE(A, p, q, r)\n    n1 = q - p + 1\n    n2 = r - q\n    let L[1..n1] and R[1..n2] be new arrays\n    for i = 1 to n1\n        L[i] = A[p + i - 1]\n    for j = 1 to n2\n        R[j] = A[q + j]\n    i = 1\n    j = 1\n    for k = p to r\n        if i &gt; n1\n            A[k] = R[j]\n            j = j + 1\n        else if j &gt; n2\n            A[k] = L[i]\n            i = i + 1\n        else if L[i] \u2264 R[j]\n            A[k] = L[i]\n            i = i + 1\n        else\n            A[k] = R[j]\n            j = j + 1\n</code></pre>"},{"location":"Chap02/2.3/#23-3","title":"2.3-3","text":"<p>Use mathematical induction to show that when $n$ is an exact power of $2$, the solution of the recurrence</p> <p>$$ T(n) = \\begin{cases}     2             &amp; \\text{if } n = 2, \\\\     2T(n / 2) + n &amp; \\text{if } n = 2^k, \\text{for } k &gt; 1 \\end{cases} $$</p> <p>is $T(n) = n\\lg n$.</p> <ul> <li>Base case</li> </ul> <p>For $n = 2^1$, $T(n) = 2\\lg 2 = 2$.</p> <ul> <li>Suppose $n = 2^k$, $T(n) = n\\lg n = 2^k \\lg 2^k = 2^kk$.</li> </ul> <p>For $n = 2^{k + 1}$,</p> <p>$$   \\begin{aligned}   T(n) &amp; = 2T(2^{k + 1} / 2) + 2^{k + 1} \\\\        &amp; = 2T(2^k) + 2^{k + 1} \\\\        &amp; = 2 \\cdot 2^kk + 2^{k + 1} \\\\        &amp; = 2^{k + 1}(k + 1) \\\\        &amp; = 2^{k + 1} \\lg 2^{k + 1} \\\\        &amp; = n\\lg n.   \\end{aligned}   $$</p> <p>By P.M.I., $T(n) = n\\lg n$, when $n$ is an exact power of $2$.</p>"},{"location":"Chap02/2.3/#23-4","title":"2.3-4","text":"<p>We can express insertion sort as a recursive procedure as follows. In order to sort $A[1..n]$, we recursively sort $A[1..n - 1]$ and then insert $A[n]$ into the sorted array $A[1..n - 1]$. Write a recurrence for the running time of this recursive version of insertion sort.</p> <p>It takes $\\Theta(n)$ time in the worst case to insert $A[n]$ into the sorted array $A[1..n - 1]$. Therefore, the recurrence</p> <p>$$ T(n) = \\begin{cases}     \\Theta(1)            &amp; \\text{if } n = 1, \\\\     T(n - 1) + \\Theta(n) &amp; \\text{if } n &gt; 1. \\end{cases} $$</p> <p>The solution of the recurrence is $\\Theta(n^2)$.</p>"},{"location":"Chap02/2.3/#23-5","title":"2.3-5","text":"<p>Referring back to the searching problem (see Exercise 2.1-3), observe that if the sequence $A$ is sorted, we can check the midpoint of the sequence against $v$ and eliminate half of the sequence from further consideration. The binary search algorithm repeats this procedure, halving the size of the remaining portion of the sequence each time. Write pseudocode, either iterative or recursive, for binary search. Argue that the worst-case running time of binary search is $\\Theta(\\lg n)$.</p> <ul> <li>Iterative:</li> </ul> <pre><code>ITERATIVE-BINARY-SEARCH(A, v, low, high)\n    while low \u2264 high\n        mid = floor((low + high) / 2)\n        if v == A[mid]\n            return mid\n        else if v &gt; A[mid]\n            low = mid + 1\n        else high = mid - 1\n    return NIL\n</code></pre> <ul> <li>Recursive:</li> </ul> <pre><code>RECURSIVE-BINARY-SEARCH(A, v, low, high)\n    if low &gt; high\n        return NIL\n    mid = floor((low + high) / 2)\n    if v == A[mid]\n        return mid\n    else if v &gt; A[mid]\n        return RECURSIVE-BINARY-SEARCH(A, v, mid + 1, high)\n    else return RECURSIVE-BINARY-SEARCH(A, v, low, mid - 1)\n</code></pre> <p>Each time we do the comparison of $v$ with the middle element, the search range continues with range halved.</p> <p>The recurrence</p> <p>$$ T(n) = \\begin{cases}     \\Theta(1)            &amp; \\text{if } n = 1, \\\\     T(n / 2) + \\Theta(1) &amp; \\text{if } n &gt; 1. \\end{cases} $$</p> <p>The solution of the recurrence is $T(n) = \\Theta(\\lg n)$.</p>"},{"location":"Chap02/2.3/#23-6","title":"2.3-6","text":"<p>Observe that the while loop of lines 5\u20137 of the $\\text{INSERTION-SORT}$ procedure in Section 2.1 uses a linear search to scan (backward) through the sorted subarray $A[i..j - 1]$. Can we use a binary search (see Exercise 2.3-5) instead to improve the overall worst-case running time of insertion sort to $\\Theta(n\\lg n)$?</p> <p>Each time the while loop of lines 5-7 of $\\text{INSERTION-SORT}$ scans backward through the sorted array $A[1..j - 1]$. The loop not only searches for the proper place for $A[j]$, but it also moves each of the array elements that are bigger than $A[j]$ one position to the right (line 6). These movements takes $\\Theta(j)$ time, which occurs when all the $j - 1$ elements preceding $A[j]$ are larger than $A[j]$. The running time of using binary search to search is $\\Theta(\\lg j)$, which is still dominated by the running time of moving element $\\Theta(j)$.</p> <p>Therefore, we can't improve the overrall worst-case running time of insertion sort to $\\Theta(n\\lg n)$.</p>"},{"location":"Chap02/2.3/#23-7-star","title":"2.3-7 $\\star$","text":"<p>Describe a $\\Theta(n\\lg n)$-time algorithm that, given a set $S$ of $n$ integers and another integer $x$, determines whether or not there exist two elements in $S$ whose sum is exactly $x$.</p> <p>First, sort $S$, which takes $\\Theta(n\\lg n)$. Then, for each element $s_i$ in $S$, $i = 1, \\dots, n$, search $A[i + 1..n]$ for $s_i' = x - s_i$ by binary search, which takes $\\Theta(\\lg n)$.</p> <ul> <li>If $s_i'$ is found, return its position;</li> <li>otherwise, continue for next iteration.</li> </ul> <p>The time complexity of the algorithm is $\\Theta(n\\lg n) + n \\cdot \\Theta(\\lg n) = \\Theta(n\\lg n)$.</p>"},{"location":"Chap02/Problems/2-1/","title":"2-1 Insertion sort on small arrays in merge sort","text":"<p>Although merge sort runs in $\\Theta(n\\lg n)$ worst-case time and insertion sort runs in $\\Theta(n^2)$ worst-case time, the constant factors in insertion sort can make it faster in practice for small problem sizes on many machines. Thus, it makes sense to coarsen the leaves of the recursion by using insertion sort within merge sort when subproblems become sufficiently small. Consider a modification to merge sort in which $n / k$ sublists of length $k$ are sorted using insertion sort and then merged using the standard merging mechanism, where $k$ is a value to be determined.</p> <p>a. Show that insertion sort can sort the $n / k$ sublists, each of length $k$, in $\\Theta(nk)$ worst-case time.</p> <p>b. Show how to merge the sublists in $\\Theta(n\\lg(n / k))$ worst-case time.</p> <p>c. Given that the modified algorithm runs in $\\Theta(nk + n\\lg(n / k))$ worst-case time, what is the largest value of $k$ as a function of $n$ for which the modified algorithm has the same running time as standard merge sort, in terms of $\\Theta$-notation?</p> <p>d. How should we choose $k$ in practice?</p> <p>a. The worst-case time to sort a list of length $k$ by insertion sort is $\\Theta(k^2)$. Therefore, sorting $n / k$ sublists, each of length $k$ takes $\\Theta(k^2 \\cdot n / k) = \\Theta(nk)$ worst-case time.</p> <p>b. We have $n / k$ sorted sublists each of length $k$. To merge these $n / k$ sorted sublists to a single sorted list of length $n$, we have to take $2$ sublists at a time and continue to merge them. The process can be visualized as a tree with $\\lg(n / k)$ levels and we compare $n$ elements in each level. Therefore, the worst-case time to merge the sublists is $\\Theta(n\\lg(n / k))$.</p> <p>c. The modified algorithm has time complexity as standard merge sort when $\\Theta(nk + n\\lg(n / k)) = \\Theta(n\\lg n)$. Assume $k = \\Theta(\\lg n)$,</p> <p>$$ \\begin{aligned} \\Theta(nk + n\\lg(n / k))     &amp; = \\Theta(nk + n\\lg n - n\\lg k) \\\\     &amp; = \\Theta(n\\lg n + n\\lg n - n\\lg(\\lg n)) \\\\     &amp; = \\Theta(2n\\lg n - n\\lg(\\lg n)) \\\\     &amp; = \\Theta(n\\lg n). \\end{aligned} $$</p> <p>d. Choose $k$ be the largest length of sublist on which insertion sort is faster than merge sort.</p>"},{"location":"Chap02/Problems/2-2/","title":"2-2 Correctness of bubblesort","text":"<p>Bubblesort is a popular, but inefficient, sorting algorithm. It works by repeatedly swapping adjacent elements that are out of order.</p> <pre><code>BUBBLESORT(A)\n    for i = 1 to A.length - 1\n        for j = A.length downto i + 1\n            if A[j] &lt; A[j - 1]\n                exchange A[j] with A[j - 1]\n</code></pre> <p>a. Let $A'$ denote the output of $\\text{BUBBLESORT}(A)$ To prove that $\\text{BUBBLESORT}$ is correct, we need to prove that it terminates and that</p> <p>$$A'[1] \\le A'[2] \\le \\cdots \\le A'[n], \\tag{2.3}$$</p> <p>where $n = A.length$. In order to show that $\\text{BUBBLESORT}$ actually sorts, what else do we need to prove?</p> <p>The next two parts will prove inequality $\\text{(2.3)}$.</p> <p>b. State precisely a loop invariant for the for loop in lines 2\u20134, and prove that this loop invariant holds. Your proof should use the structure of the loop invariant proof presented in this chapter.</p> <p>c. Using the termination condition of the loop invariant proved in part (b), state a loop invariant for the for loop in lines 1\u20134 that will allow you to prove inequality $\\text{(2.3)}$. Your proof should use the structure of the loop invariant proof presented in this chapter.</p> <p>d. What is the worst-case running time of bubblesort? How does it compare to the running time of insertion sort?</p> <p>a. $A'$ consists of the elements in $A$ but in sorted order.</p> <p>b. Loop invariant: At the start of each iteration of the for loop of lines 2-4, the subarray $A[j..n]$ consists of the elements originally in $A[j..n]$ before entering the loop but possibly in a different order and the first element $A[j]$ is the smallest among them.</p> <p>Initialization: Initially the subarray contains only the last element $A[n]$, which is trivially the smallest element of the subarray.</p> <p>Maintenance: In every step we compare $A[j]$ with $A[j - 1]$ and make $A[j - 1]$ the smallest among them. After the iteration, the length of the subarray increases by one and the first element is the smallest of the subarray.</p> <p>Termination: The loop terminates when $j = i$. According to the statement of loop invariant, $A[i]$ is the smallest among $A[i..n]$ and $A[i..n]$ consists of the elements originally in $A[i..n]$ before entering the loop.</p> <p>c. Loop invariant: At the start of each iteration of the for loop of lines 1-4, the subarray $A[1..i \u2212 1]$ consists of the $i - 1$ smallest elements in $A[1..n]$ in sorted order. $A[i..n]$ consists of the $n - i + 1$ remaining elements in $A[1..n]$.</p> <p>Initialization: Initially the subarray $A[1..i \u2212 1]$ is empty and trivially this is the smallest element of the subarray.</p> <p>Maintenance: From part (b), after the execution of the inner loop, $A[i]$ will be the smallest element of the subarray $A[i..n]$. And in the beginning of the outer loop, $A[1..i \u2212 1]$ consists of elements that are smaller than the elements of $A[i..n]$, in sorted order. So, after the execution of the outer loop, subarray $A[1..i]$ will consists of elements that are smaller than the elements of $A[i + 1..n]$, in sorted order.</p> <p>Termination: The loop terminates when $i = A.length$. At that point the array $A[1..n]$ will consists of all elements in sorted order.</p> <p>d. The $i$th iteration of the for loop of lines 1-4 will cause $n \u2212 i$ iterations of the for loop of lines 2-4, each with constant time execution, so the worst-case running time of bubble sort is $\\Theta(n^2)$ which is same as the worst-case running time of insertion sort.</p>"},{"location":"Chap02/Problems/2-3/","title":"2-3 Correctness of Horner's rule","text":"<p>The following code fragment implements Horner's rule for evaluating a polynomial</p> <p>$$ \\begin{aligned} P(x) &amp; = \\sum_{k = 0}^n a_k x^k \\\\      &amp; = a_0 + x(a_1 + x (a_2 + \\cdots + x(a_{n - 1} + x a_n) \\cdots)), \\end{aligned} $$</p> <p>given the coefficients $a_0, a_1, \\ldots, a_n$ and a value of $x$:</p> <pre><code>y = 0\nfor i = n downto 0\n    y = a[i] + x * y\n</code></pre> <p>a. In terms of $\\Theta$-notation, what is the running time of this code fragment for Horner's rule?</p> <p>b. Write pseudocode to implement the naive polynomial-evaluation algorithm that computes each term of the polynomial from scratch. What is the running time of this algorithm? How does it compare to Horner's rule</p> <p>c. Consider the following loop invariant: At the start of each iteration of the for loop of lines 2-3,</p> <p>$$y = \\sum_{k = 0}^{n - (i + 1)} a_{k + i + 1} x^k.$$</p> <p>Interpret a summation with no terms as equaling $0$. Following the structure of the loop invariant proof presented in this chapter, use this loop invariant to show that, at termination, $y = \\sum_{k = 0}^n a_k x^k$.</p> <p>d. Conclude by arguing that the given code fragment correctly evaluates a polynomial characterized by the coefficients $a_0, a_1, \\ldots, a_n$.</p> <p>a. $\\Theta(n)$.</p> <p>b.</p> <pre><code>NAIVE-HORNER()\n    y = 0\n    for k = 0 to n\n        temp = 1\n        for i = 1 to k\n            temp = temp * x\n        y = y + a[k] * temp\n</code></pre> <p>The running time is $\\Theta(n^2)$, because of the nested loop. It is obviously slower.</p> <p>c. Initialization: It is pretty trivial, since the summation has no terms which implies $y = 0$.</p> <p>Maintenance: By using the loop invariant, in the end of the $i$-th iteration, we have</p> <p>$$ \\begin{aligned} y &amp; = a_i + x \\sum_{k = 0}^{n - (i + 1)} a_{k + i + 1} x^k \\\\   &amp; = a_i x^0 + \\sum_{k = 0}^{n - i - 1} a_{k + i + 1} x^{k + 1} \\\\   &amp; = a_i x^0 + \\sum_{k = 1}^{n - i} a_{k + i} x^k \\\\   &amp; = \\sum_{k = 0}^{n - i} a_{k + i} x^k. \\end{aligned} $$</p> <p>Termination: The loop terminates at $i = -1$. If we substitute,</p> <p>$$y = \\sum_{k = 0}^{n - i - 1} a_{k + i + 1} x^k = \\sum_{k = 0}^n a_k x^k.$$</p> <p>d. The invariant of the loop is a sum that equals a polynomial with the given coefficients.</p>"},{"location":"Chap02/Problems/2-4/","title":"2-4 Inversions","text":"<p>Let $A[1..n]$ be an array of $n$ distinct numbers. If $i &lt; j$ and $A[i] &gt; A[j]$, then the pair $(i, j)$ is called an inversion of $A$.</p> <p>a. List the five inversions in the array $\\langle 2, 3, 8, 6, 1 \\rangle$.</p> <p>b. What array with elements from the set $\\{1, 2, \\ldots, n\\}$ has the most inversions? How many does it have?</p> <p>c. What is the relationship between the running time of insertion sort and the number of inversions in the input array? Justify your answer.</p> <p>d. Give an algorithm that determines the number of inversions in any permutation of $n$ elements in $\\Theta(n\\lg n)$ worst-case time. ($\\textit{Hint:}$ Modify merge sort).</p> <p>a. $(1, 5)$, $(2, 5)$, $(3, 4)$, $(3, 5)$, $(4, 5)$.</p> <p>b. The array $\\langle n, n - 1, \\dots, 1 \\rangle$ has the most inversions $(n - 1) + (n - 2) + \\cdots + 1 = n(n - 1) / 2$.</p> <p>c. The running time of insertion sort is a constant times the number of inversions. Let $I(i)$ denote the number of $j &lt; i$ such that $A[j] &gt; A[i]$. Then $\\sum_{i = 1}^n I(i)$ equals the number of inversions in $A$.</p> <p>Now consider the while loop on lines 5-7 of the insertion sort algorithm. The loop will execute once for each element of $A$ which has index less than $j$ is larger than $A[j]$. Thus, it will execute $I(j)$ times. We reach this while loop once for each iteration of the for loop, so the number of constant time steps of insertion sort is $\\sum_{j = 1}^n I(j)$ which is exactly the inversion number of $A$.</p> <p>d. We'll call our algorithm $\\text{COUNT-INVERSIONS}$ for modified merge sort. In addition to sorting $A$, it will also keep track of the number of inversions.</p> <p>$\\text{COUNT-INVERSIONS}(A, p, r)$ sorts $A[p..r]$ and returns the number of inversions in the elements of $A[p..r]$, so $left$ and $right$ track the number of inversions of the form $(i, j)$ where $i$ and $j$ are both in the same half of $A$.</p> <p>$\\text{MERGE-INVERSIONS}(A, p, q, r)$ returns the number of inversions of the form $(i, j)$ where $i$ is in the first half of the array and $j$ is in the second half. Summing these up gives the total number of inversions in $A$. The runtime of the modified algorithm is $\\Theta(n\\lg n)$, which is same as merge sort since we only add an additional constant-time operation to some of the iterations in some of the loops.</p> <pre><code>COUNT-INVERSIONS(A, p, r)\n    if p &lt; r\n        q = floor((p + r) / 2)\n        left = COUNT-INVERSIONS(A, p, q)\n        right = COUNT-INVERSIONS(A, q + 1, r)\n        inversions = MERGE-INVERSIONS(A, p, q, r) + left + right\n        return inversions\n</code></pre> <pre><code>MERGE-INVERSIONS(A, p, q, r)\n    n1 = q - p + 1\n    n2 = r - q\n    let L[1..n1 + 1] and R[1..n2 + 1] be new arrays\n    for i = 1 to n1\n        L[i] = A[p + i - 1]\n    for j = 1 to n2\n        R[j] = A[q + j]\n    L[n1 + 1] = \u221e\n    R[n2 + 1] = \u221e\n    i = 1\n    j = 1\n    inversions = 0\n    for k = p to r\n        if L[i] &lt;= R[j]\n            A[k] = L[i]\n            i = i + 1\n        else\n            inversions = inversions + n1 - i + 1\n            A[k] = R[j]\n            j = j + 1\n    return inversions\n</code></pre>"}]}